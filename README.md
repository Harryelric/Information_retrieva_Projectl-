# Information_retrieva_Projectl-
新闻检索：爬虫定向采集3-4个网页，实现网页信息的抽取、检索和索引。网页个数不少于10个，能按时间、相关度、热度等属性进行排序，并实现相似主题的自动聚类。可以实现：有相关搜索推荐、snippet生成、结果预览(鼠标移到相关结果， 能预览)功能
数据10万条网易新闻网页、倒排索引等数据 baidu网盘http://pan.baidu.com/s/1gfkDb4B 
    下载后，将data文件夹放在Information_retrieva_Projectl-目录下即可
#使用方法： 交互式查询：linux下cd 至web/ 文件夹下 终端下键入python main.py 浏览器中打开：http://0.0.0.0:8080/ #参考文献： 1.scrapy手册 http://scrapy-chs.readthedocs.org/zh_CN/1.0/intro/tutorial.html 2.webpy 手册 http://webpy.org/ #运行效果![12](https://user-images.githubusercontent.com/83235895/121847103-41160680-cd12-11eb-8525-7ce1153afb46.png)
![2016-05-29 20_10_07____________](https://user-images.githubusercontent.com/83235895/121847117-47a47e00-cd12-11eb-8322-0d6ee4077c70.png)
![2016-05-29 011426屏幕截图](https://user-images.githubusercontent.com/83235895/121847148-525f1300-cd12-11eb-9288-b2bb6c29bdb5.png)
![121](https://user-images.githubusercontent.com/83235895/121847157-58ed8a80-cd12-11eb-8b9f-19953f3791d1.png)
！！！更多技术细节、学习资料请查看report文件。
